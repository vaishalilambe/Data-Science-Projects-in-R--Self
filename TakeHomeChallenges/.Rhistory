local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
utils:::menuInstallPkgs()
utils:::menuInstallPkgs()
chooseCRANmirror()
install package
install packages("foreign")
q()
setwd("C:/Users/Admin/Documents/DataScience/PracticeProject/TakeHomeChallenges")
require(dplyr)
require(rpart)
require(ggplot2)
user = read.csv("user_table.csv")
test = read.csv("test_table.csv")
length(unique(test$user_id)) == length(test$user_id) # are there dupes?
length(unique(user$user_id)) == length(user$user_id) # are there dupes?
length(user$user_id) - length(test$user_id) # everyone in one table also in the
data = merge(test,user, by = "user_id", all.x = TRUE) # this way we don't lose data
data$date = as.Date(data$date)
summary(data)
data_conversion_country = data %>%
group_by(country) %>%
summarize( conversion = mean(conversion[test == 0]))%>% # we check the old version
arrange (desc(conversion))
head(data_conversion_country)
split is ~50/50.
data_test = subset(data, country != "Spain") #nothing changed in Spain, so no poin
t.test(data_test$conversion[data_test$test == 1], data_test$conversion[data_test$test == 0])
data_test_by_day = data_test %>%
group_by(date) %>%
summarize(test_vs_control = mean(conversion[test==1])/
mean(conversion[test==0])
)
qplot(date, test_vs_control, data= data_test_by_day, geom = "line")
tree = rpart(test ~ .,data_test[,-8], #we remove conversion. Doesn't matter now.
control = rpart.control(minbucket = nrow(data_test)/100, maxdepth =
2)ô€€ƒ# we only look for segments representing at least 1% of the populations.
)
tree = rpart(test ~ .,data_test[,-8], #we remove conversion. Doesn't matter now.
control = rpart.control(minbucket = nrow(data_test)/100, maxdepth =2)ô€€ƒ# we only look for segments representing at least 1% of the populations.
)
tree = rpart(test ~ .,data_test[,-8], #we remove conversion. Doesn't matter now.
control = rpart.control(minbucket = nrow(data_test)/100, maxdepth =2))ô€€ƒ# we only look for segments representing at least 1% of the population.)
tree = rpart(test ~ .,data_test[,-8], #we remove conversion. Doesn't matter now.
control = rpart.control(minbucket = nrow(data_test)/100, maxdepth =2))
tree # here we are not too interested
data_test_country = data_test %>%
group_by(country) %>%
summarize(p_value = t.test( conversion[test==1],conversion[test==0])$p.value,
conversion_test = t.test( conversion[test==1],conversion[test==0])$estimate[1],
conversion_control = t.test( conversion[test==1],conversion[test==0])$estimate[2]) %>%
arrange (p_value)
data_test_country
require(dplyr)
require(rpart)
require(ggplot2)
require(scales)
data = read.csv("employee_retention_dataí¯€ô€ô€•ô€Šô€ô€ô€€ô€…ô€‚ô€•ô€‚ô€€ô€„ô€”ô€—") #read data set
str(data) #check the structure
data = read.csv("employee_retention_data.csv")
str(data) #check the structure
data$company_id = as.factor(data$company_id) # this is a categorical var
data$join_date = as.Date(data$join_date) #make it a date
data$quit_date = as.Date(data$quit_date) #make it a date
summary(data) # everything seems to make sense, some simple plots would help double check that
unique_dates = seq(as.Date("2011/01/24"), as.Date("2015/12/13"), by = "day") # create list of unique dates for the table
unique_companies = unique(data$company_id) #ceate list of unique companies
data_headcount = merge(unique_dates, unique_companies, by = NULL) #cross join so I get all combinations of dates and companies. Will need it later.
colnames(data_headcount) = c("date", "company_id") #now I get for each day/company, how many people quit/got hired on that day
data_join = data %>%
group_by(join_date, company_id) %>%
summarise(join_count = length(join_date))
data_quit = data %>%
group_by(quit_date, company_id) %>%
summarise(quit_count = length(quit_date))
data_headcount = merge (data_headcount, data_join,
by.x = c("date", "company_id"),
by.y = c("join_date", "company_id"),
all.x = TRUE)
data_headcount = merge (data_headcount, data_quit,
by.x = c("date", "company_id"),
by.y = c("quit_date", "company_id"),
all.x = TRUE)
data_headcount$join_count[is.na(data_headcount$join_count)] = 0
data_headcount$quit_count[is.na(data_headcount$quit_count)] = 0
data_headcount = data_headcount %>%
group_by(company_id) %>%
mutate ( join_cumsum = cumsum(join_count),
quit_cumsum = cumsum(quit_count)
)
data_headcount$count = data_headcount$join_cumsum - data_headcount$quit_cumsum
data_headcount_table = data.frame(data_headcount[, c("date", "company_id","counô€€ƒ
t")])
data_headcount_table = data.frame(data_headcount[, c("date", "company_id","count")])
loop_cumsum = c() #intialize empty vector
loop_date = c()
loop_company = c()
for (i in seq(as.Date("2011/01/24"), as.Date("2015/12/13"), by = "day")) { #loop through all days
for (j in unique(data$company_id)){ # loop through all companies
tmp_join = nrow(subset(data, join_date <= i & company_id == j)) # count joins until that day
tmp_quit = nrow(subset(data, quit_date <= i & company_id == j)) # count quits
loop_cumsum = c(loop_cumsum, tmp_join - tmp_quit )
loop_date = c(loop_date, i)
loop_company = c(loop_company, j)
}
data_headcount_table_loop = data.frame(date = as.Date(loop_date, origin = '1970-01-01'), #fix R date
company_id = loop_company,
count = loop_cumsum)
}
identical (data_headcount_table[order(data_headcount_table[,1],
as.numeric(as.character(data_headcount_table[,2] ))),],
data_headcount_table[order(data_headcount_table[,1],
as.numeric(as.character(data_headcount_table[,2]))),]
)
data$employment_length = as.numeric(data$quit_date - data$join_date)
year
data$week_of_year = as.numeric(format(data$quit_date, "%U"))
hist(data$employment_length, breaks = 100)
hist(data$week_of_year, breaks = length(unique(data$week_of_year)))
data = subset(data, data$join_date < as.Date("2015/12/13") - (365 + 31)) # only keep people who had ô€ˆô€‘ô€’ô€˜ô€Šô€‹ time to age
data$early_quitter = as.factor(ifelse( is.na(data$quit_date) | as.numeric(data$quit_date - data$join_date) > 396, 0, 1))
tree = rpart(early_quitter ~ .,data[, c("company_id", "dept", "seniority", "early_quitter", "salary")], #put salary
control = rpart.control(minbucket = 30, maxdepth = 3 , cp = 0.000001),
parms = list(prior = c(0.5,0.5))
)
tree #we are not too interested in predictive poweô€•, we are mainly using thtreetr as a descriptive stat tool.
data$salary_percentile = cut(data$salary, breaks = quantile(data$salary, probs = seq(0, 1, 0.02)),include.lowest = TRUE, labels = 1:50)
data_proportion_by_percentile = data %>%
group_by(salary_percentile) %>%
summarize(proportion_early_quitters = length(early_quitter[early_quitter==1])/length(early_quitter))
qplot(salary_percentile, proportion_early_quitters, data=data_proportion_by_percentile, geom="line", group =1) + scale_x_discrete(breaks = seq(1,50, by=2))
